{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Querying Groq LLM for additional insights...\n",
      "\n",
      "Groq LLM Response:\n",
      "The text discusses Artificial Intelligence (AI) and its various types, functionalities, and applications. Here are the key points summarized:\n",
      "\n",
      "**Types of AI based on Ability:**\n",
      "\n",
      "1. **Artificial Narrow AI (Weak AI)**: exists today, can be trained to perform a single task, and is faster and better than humans in that task.\n",
      "2. **Artificial General Intelligence (AGI) (Strong AI)**: theoretical, can learn and perform any intellectual task that a human can, without needing human training.\n",
      "3. **Super AI**: theoretical, would surpass human cognitive abilities and have artificial superintelligence.\n",
      "\n",
      "**Types of AI based on Functionality:**\n",
      "\n",
      "1. **Reactive Machines**: basic type of AI, reacts to current scenarios without storing memories or past experiences.\n",
      "2. **Limited Memory**: can store past experiences or data for a short period, used in self-driving cars.\n",
      "3. **Theory of Mind**: AI that understands human emotions, people, and beliefs, and can interact socially like humans (still in development).\n",
      "4. **Self-Awareness**: AI with its own consciousness, sentiments, and self-awareness, smarter than humans (hypothetical concept).\n",
      "\n",
      "**Applications of AI:**\n",
      "\n",
      "1. Internet of Things (IoT)\n",
      "2. Deep Learning\n",
      "3. Social Network Analysis\n",
      "4. Audio Analytics\n",
      "5. Machine Learning\n",
      "6. Visualization\n",
      "7. E-commerce\n",
      "\n",
      "Overall, the text provides an overview of AI, its types, functionalities, and potential applications, highlighting the current state of AI and its future possibilities.\n",
      "Summarized text saved to output_ai.txt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Groq API key\n",
    "load_dotenv()\n",
    "\n",
    "# Groq API key from environment variable\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "# === Helper Functions === #\n",
    "def load_text(file_path):\n",
    "    \"\"\"Load text from a file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading text file: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean the text by removing empty lines.\"\"\"\n",
    "    cleaned_text = \"\\n\".join([line for line in text.splitlines() if line.strip() != \"\"])\n",
    "    return cleaned_text\n",
    "\n",
    "def query_groq_llm(prompt, context, max_tokens=500):\n",
    "    \"\"\"Send a prompt and context to the Groq LLM chat completion API.\"\"\"\n",
    "    try:\n",
    "        url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {GROQ_API_KEY}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        payload = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are an assistant helping summarize and query text.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"{prompt}\\n\\nContext:\\n{context}\"}\n",
    "            ],\n",
    "            \"model\": \"llama-3.3-70b-versatile\",  # Replace with your desired model\n",
    "            \"max_tokens\": max_tokens,  # Adjust based on your needs\n",
    "            \"temperature\": 0.7  # Adjust randomness\n",
    "        }\n",
    "        response = requests.post(url, json=payload, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.json().get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"No response\")\n",
    "        else:\n",
    "            print(f\"Groq API Error: {response.status_code}, {response.text}\")\n",
    "            return f\"An error occurred while fetching a response from Groq: {response.status_code}, {response.text}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error communicating with Groq API: {e}\")\n",
    "        return f\"An error occurred while fetching a response from Groq: {e}\"\n",
    "\n",
    "# === Main Functionality === #\n",
    "def process_text_file(file_path, output_txt_path):\n",
    "    \"\"\"Process the text file and generate a clean, compacted educational text file.\"\"\"\n",
    "    text = load_text(file_path)\n",
    "    if not text:\n",
    "        print(\"Failed to load text.\")\n",
    "        return\n",
    "\n",
    "    # Clean the text\n",
    "    cleaned_text = clean_text(text)\n",
    "\n",
    "    # Use a generic query to summarize the entire content\n",
    "    user_query = \"Summarize the key points of the text.\"\n",
    "\n",
    "    # Use Groq API for enhanced summarization\n",
    "    print(\"\\nQuerying Groq LLM for additional insights...\")\n",
    "    llm_response = query_groq_llm(user_query, cleaned_text, max_tokens=500)\n",
    "    print(\"\\nGroq LLM Response:\")\n",
    "    print(llm_response)\n",
    "\n",
    "    # Save the summarized text to a file\n",
    "    with open(output_txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(llm_response)\n",
    "\n",
    "# === Run the System === #\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"summary_ai.txt\"  # Replace with your text file\n",
    "    output_txt_path = \"output_ai.txt\"\n",
    "    process_text_file(file_path, output_txt_path)\n",
    "    print(f\"Summarized text saved to {output_txt_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
